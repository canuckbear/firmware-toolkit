#
# The contents of this file are subject to the Apache 2.0 license you may not
# use this file except in compliance with the License.
#
# Software distributed under the License is distributed on an "AS IS" basis,
# WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
# for the specific language governing rights and limitations under the
# License.
#
#
# Copyright 2016 DFT project (http://www.debianfirmwaretoolkit.org).  
# All rights reserved. Use is subject to license terms.
#
# Debian Firmware Toolkit is the new name of Linux Firmware From Scratch
# Copyright 2014 LFFS project (http://www.linuxfirmwarefromscratch.org).  
#
#
# Contributors list :
#
#    William Bonnet     wllmbnnt@gmail.com, wbonnet@theitmakers.com
#
#

import logging, os, subprocess, tarfile, shutil
from datetime import datetime

#
#    Class BuildBaseOS
#
class BuildBaseOS: 
    '''This class implements method needed to create the base OS

       The "base OS" is the initial installation of Debian (debootstrap) which
       is used to apply ansible playbooks.

       The methods implemented in this class provides what is needed to :
         . create the debootstrap (chrooted environment)
         . handle filesystems like dev and proc in the chrooted environment
         . copy DFT and project specific templates into /dft_bootstrap
         . run ansible in the chroot
         . cleanup things when installation is done
    '''

    def __init__(self):
        '''Default constructor
        '''

        # Default mirror to use. It has to be the URL of a valid Debian mirror
        # It is used by debootstrap as its sources of packages.
        self.pkg_archive_url = "http://mirrors/debian/"

        # Target version to use when building the debootstrap. It has to be
        # a Debian version (jessie, stretch, etc.)
        self.target_version = "stretch"

        # Stores the target architecture
        # TODO should we have a list here ? 
        self.target_arch = "armhf"

        # Retrieve the architecture of the host
        self.host_arch = subprocess.check_output("dpkg --print-architecture", shell=True).decode('UTF-8').rstrip()

        # Boolean used to flag the use of QEMU static
        self.use_qemu_static =  (self.host_arch != self.target_arch)

        # Debootstrap target to use (minbase or buildd)
        self.debootstrap_target = "minbase"

        # Boolean used to flag if the cache archive should used instead 
        # of doing a real debootstrap installation
        self.use_rootfs_cache = True

        # Boolean used to flag if the cache archive should used updated
        # after doing a real debootstrap installation
        self.update_rootfs_cache = True

        # Boolean used to flag if the cache archive is available. This value 
        # is set by the setup_configuration method. Default is False, to 
        # ensure it will be rebuild
        self.rootfs_cache_is_available = False

        # Timestamp is generated by the setup_configuration method
        self.timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")

        # Generates the path to the rootfs mountpoint
        rootfs_base_workdir = "/tmp/rootfs_mountpoint"
        rootfs_image_name   = self.target_arch + "-" + self.target_version + "-" + self.timestamp

        # Stores the path to the rootfs mountpoint used by debootstrap
        self.rootfs_mountpoint = rootfs_base_workdir + "/" + rootfs_image_name
  
        # Path to the directory ued to store cache archives
        self.rootfs_generator_cachedir = "/tmp"

        # Current log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
        self.log_level = "INFO"

        # Name of the current baseos being produced. Used in rootfs mount
        # point path and archive name generation
        self.target_name = "test"

        # Generate the cache archive filename
        self.archive_filename = self.rootfs_generator_cachedir + "/" + self.target_arch + "-" +  self.target_version + "-" +  self.target_name + ".tar"

        logging.basicConfig(level=self.log_level)

    def install_baseos(self):
        '''This method implement the logic of generating the rootfs. It calls
        dedicated method for each step. The main steps are :

        . setting up configuration
        . extracting cache archive content or running debootstrap
        . setup QEMU and run stage 2 if needed
        . update cache if needed
        . deploy DFT Ansible templates, and run Ansible to do confiugration
        . cleanup installation files
        . cleanup QEMU
        '''

        # Ensure target rootfs mountpoint exists and is a dir
        if os.path.isdir(self.rootfs_mountpoint) == False:
            os.makedirs(self.rootfs_mountpoint)
        else:
            logging.warn("Target rootfs mount point already exists : " + self.rootfs_mountpoint)

        # Check if the archive has to be used instead of doing a debootstraping
        # for real. Only if the archive exist...
        if self.use_rootfs_cache == True and self.rootfs_cache_is_available == True:
            self.fake_generate_debootstrap_rootfs()
        else:
            # In any other cases, do a real debootstrap call
            self.generate_debootstrap_rootfs()

        # Ã¾est the archive has to be updated
        if self.update_rootfs_cache == True:
            # But only do it if we haven't bee using the cache, or it
            # would be extracted, then archived again.
            if self.use_rootfs_cache == True:
                self.update_rootfs_archive()

        # Generate a unique build timestamp into /etc/dft_version 
        self.generate_build_number()

        # Generate the APT sources that will be used during the Ansible phase
        self.generate_apt_sources_configuration()

#TODO
#        Copy DFT stuff

#TODO
#        Run ansible

        # Once installation has been played, we need to do some cleanup
        # like ensute that no mount bind is still mounted, or delete the
        # DFT ansible files
        self.cleanup_installation_files()

        # Remove QEMU if it has been isntalled. It has to be done in the end
        # since some cleanup tasks could need QEMU
        if self.use_qemu_static == True:
            self.cleanup_qemu()

    def setup_qemu(self):
        '''This method remove the QEMU static binary which has been previously 
        copied to the target 
        '''

        # We should not execute if the flag is not set. Should have already 
        # been tested, but double check by security
        if self.use_qemu_static != True:
            return

        # Copy the QEMU binary to the target, using root privileges
        if   self.target_arch == "armhf":     qemu_target_arch = "arm"
        elif self.target_arch == "armel":     qemu_target_arch = "arm"
        else:                                 qemu_target_arch = self.target_arch

        logging.info("Setting up QEMU for arch " + self.target_arch + "(/usr/bin/qemu-" + qemu_target_arch + "-static)")
        os.system("sudo cp /usr/bin/qemu-" + qemu_target_arch + "-static " + self.rootfs_mountpoint + "/usr/bin/")

    def cleanup_qemu(self):
        '''This method copy the QEMU static binary to the target 
        '''

        # We should not execute if the flag is not set. Should have already 
        # been tested, but double check by security
        if self.use_qemu_static != True:
            return

        # Copy the QEMU binary to the target, using root privileges
        if   self.target_arch == "armhf":     qemu_target_arch = "arm"
        elif self.target_arch == "armel":     qemu_target_arch = "arm"
        else:                                 qemu_target_arch = self.target_arch
        
        # Execute the file removal with root privileges
        logging.info("Cleaning QEMU for arch " + self.target_arch + "(/usr/bin/qemu-" + qemu_target_arch + "-static)")
        os.system("sudo rm " + self.rootfs_mountpoint + "/usr/bin/qemu-" + qemu_target_arch + "-static")

    def cleanup_installation_files(self):
        '''This method is incharge of cleaning processes after Ansible has been 
        launched. In some case some daemons are still running inside the 
        chroot, and they have to be stopped manually, or even killed in order
        to be able to umount /dev/ and /proc from inside the chroot
        '''
        logging.info("Starting to cleanup installation files")
        pass

    def generate_build_number(self):
        '''
        '''

        logging.info("Starting to generate build number")

        # Open the file and writes configuration in it
        buildnumber_filepath = self.rootfs_mountpoint + "/etc/dft_version"
        buildnumber_file = open(buildnumber_filepath, "w")
        buildnumber_file.write("Acquire::Check-Valid-Until \"0\"")
        buildnumber_file.close()

        # Change file owner to root:root
        shutil.chown(buildnumber_filepath, 0, 0)

    
    def update_rootfs_archive(self):
        '''This methods update (delete then recreate) the rootfs archive after
        doing a real debootstrap installation.

        Archive is not updated if cache has been used instead of debootstraping
        otherwise it would generate the same archive'''
        logging.info("Starting to update rootfs archive")

        # Remove existing archive before generating the new one
        try:
            if os.path.isfile(self.archive_filename) == True:
                logging.info("removing previous archive file : " + self.archive_filename)
                os.remove(self.archive_filename)

        # Catch file removal exceptions
        except OSError as e:
            print ("Error: %s - %s." % (e.filename, e.strerror))

        # Create the new archive
        cache_archive = tarfile.open(self.archive_filename)
        cache_archive.add(name=self.rootfs_mountpoint)
        cache_archive.close()

    def fake_generate_debootstrap_rootfs(self):
        logging.info("Starting to fake generate debootstrap rootfs")

        # Check that the archive exists
        if os.path.isfile(self.archive_filename) == False:
            logging.warning("Cache has been activate and archive file does not exist : " + self.archive_filename)
            return False

        # Extract tar file to rootfs mountpoint
        logging.info("extracting archive : " + self.archive_filename)
        cache_archive = tarfile.open(self.archive_filename)
        cache_archive.extractall(path=self.rootfs_mountpoint)
        cache_archive.close()
        pass

    def generate_debootstrap_rootfs(self):
        '''
        '''

        logging.info("Starting to generate debootstrap rootfs")

        # Generate the base debootstrap command
        debootstrap_command  = "sudo debootstrap --no-check-gpg"

        # Add the foreign and arch only if they are different from host, and
        # thus if use_qemu_static is True
        if self.use_qemu_static == True:
            debootstrap_command += " --foreign --arch=" + self.target_arch 

        # Add the target, mount point and repository url to the debootstrap command
        debootstrap_command += " " +  self.target_version + " " + self.rootfs_mountpoint + " " + self.pkg_archive_url

        # Finally run the subprocess
        logging.info("doing debootstrap stage 1")
        logging.debug("running : " + debootstrap_command)
        subprocess.run(debootstrap_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, check=True)

        if self.use_qemu_static == True:
            debootstrap_command += " --foreign --arch=" + self.target_arch 

        # Check if we are working with foreign arch, then ... 
        if self.use_qemu_static == True:
            # QEMU is used, and we have to install it into the target
            self.setup_qemu()

            # And second stage must be run
            logging.info("doing debootstrap stage 2")
            logging.debug("running : " + debootstrap_command)
            debootstrap_command  = "LANG=C sudo chroot " + self.rootfs_mountpoint + " /debootstrap/debootstrap --second-stage"
            subprocess.run(debootstrap_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, check=True)


        # Mount bind /proc into the rootfs mountpoint
        mount_command = "sudo mount --bind --make-rslave /proc " + self.rootfs_mountpoint + "}/proc"
        logging.debug("running : " + mount_command)
        subprocess.run(mount_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, check=True)

        # Mount bind /dev/pts into the rootfs mountpoint
        mount_command = "sudo mount --bind --make-rslave /dev/pts " + self.rootfs_mountpoint + "}/dev/pts"
        logging.debug("running : " + mount_command)
        subprocess.run(mount_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, check=True)

        # Mount bind /dev/shm into the rootfs mountpoint
        mount_command = "sudo mount --bind --make-rslave /dev/shm " + self.rootfs_mountpoint + "}/dev/shm"
        logging.debug("running : " + mount_command)
        subprocess.run(mount_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, check=True)

        # Update the APT sources
        self.generate_apt_sources_configuration()

        # Then update the list of packages
        apt_command = "sudo chroot " + self.rootfs_mountpoint + " /usr/bin/apt-get update"
        logging.debug("running : " + apt_command)
        subprocess.run(apt_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, check=True)
 
        # Install extra packages into the chroot
        apt_command = "sudo chroot " + self.rootfs_mountpoint + " /usr/bin/apt-get install --no-install-recommends --yes --allow-unauthenticated apt-utils ansible"
        logging.debug("running : " + apt_command)
        subprocess.run(apt_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, check=True)


    def generate_apt_sources_configuration(self):
        ''' This method has two functions, configure APT sources and configure
        apt to ignore validity check on expired repositories

        The method generates a file named 10no-check-valid-until which is 
        placed in the apt config directory. It is used to deactivate validity
        check on repository during installation, so a mirror can still be used
        even if it is expired. This use case happens often when mirrors cannot
        be sync'ed automatically from the internet

        Second part of the methods iterate the repositories from configuration
        file and generates sources.list
        '''
        #TODO : remove validity check after generation ? => flag ? 
        logging.info("Starting to generate APT sources configuration")

        # Generate the file path
        apt_conf_filepath = self.rootfs_mountpoint + "/etc/apt/apt.conf.d/10no-check-valid-until"

        # Open the file and writes configuration in it
        apt_conf_file = open(apt_conf_filepath, "w")
        apt_conf_file.write("Acquire::Check-Valid-Until \"0\"")
        apt_conf_file.close()

        # Change file owner to root:root
        shutil.chown(apt_conf_filepath, 0, 0)

        # Generate the file path
        sources_filepath = self.rootfs_mountpoint + "/etc/apt/sources.list"

        # Open the file and writes configuration in it
        sources_file = open(apt_conf_filepath, "w")
        sources_file.write("Acquire::Check-Valid-Until \"0\"")
        sources_file.write("deb " + self.debian_mirror_url + "/debian " + self.target_version + " main contrib non-free")
        sources_file.write("deb " + self.debian_mirror_url + "/debian-security " + self.target_version + "/updates main contrib non-free")
        sources_file.write("deb " + self.debian_mirror_url + "/debian " + self.target_version + "-updates main contrib non-free")
        sources_file.close()

        # Change file owner to root:root
        shutil.chown(sources_filepath, 0, 0)